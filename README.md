# Awesome Gesture Generation [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A curated list of Awesome **Gesture Generation** resources inspired by [awesome-NeRF](https://github.com/awesome-NeRF/awesome-NeRF).

## Table of Contents

- [1. Survey](#survey)
- [2. Papers](#papers)
- [3. Dataset](#dataset)
- [4. Toolkit](#toolkit)
- [5. Talks](#talks)
  - [Algorithms and Design Patterns](#algorithms-and-design-patterns)
  - [Audio](#audio)
- [5. Implementations](#implementations)
- [6. Resources](#resources)
  - [Books](#books)
  - [Newsletters](#newsletters)
  - [Podcasts](#podcasts)
  - [Websites](#websites)
- [Contributing](#contributing)

---

**PapersWithCode**

- Gesture Generation : [https://paperswithcode.com/task/gesture-generation](https://paperswithcode.com/task/gesture-generation)

## <a name="survey">1. Survey</a>

<details open>
<summary>Comprehensive preview</summary>

- [A Comprehensive Review of Data-Driven Co-Speech Gesture Generation](https://arxiv.org/abs/2301.05339) | [github](https://github.com/google/mipnerf) | [web](https://www.ea.com/seed/news/genea-challenge-2022)

</details>

<details open>
<summary>GENEA Challenge</summary>

- [The GENEA Challenge 2022: A large evaluation of data-driven co-speech gesture generation](https://arxiv.org/abs/2208.10441) | [homepage](https://youngwoo-yoon.github.io/GENEAchallenge2022/) | [video](https://www.youtube.com/watch?v=4n02wXGGnd0)

- [GENEA Workshop 2021: The 2nd Workshop on Generation and Evaluation of Non-verbal Behaviour for Embodied Agents](https://dl.acm.org/doi/10.1145/3462244.3480983) | [homepage](https://genea-workshop.github.io/2021/)

- [The GENEA Challenge 2020: A large, crowdsourced evaluation of gesture generation systems on common data](https://arxiv.org/abs/2102.11617) | [homepage](https://svito-zar.github.io/GENEAchallenge2020/) | [video](https://www.youtube.com/watch?v=QmaoKRzoVwM) | [github](https://github.com/Svito-zar/genea_numerical_evaluations)
</details>

## <a name="papers">2. Papers</a>

<!-- ************************* Base-paper ************************* -->
<details open>
<summary>Base-paper</summary>

- []()
</details>
<!-- ************************* Base-paper ************************* -->

<!-- ************************* GENEA Challenge ************************* -->
<details open>
<summary>GENEA Challenge</summary>

**2023 - Accepted papers****

    - [Evaluating Data-Driven Co-Speech Gestures of Embodied Conversational Agents through Real-Time Interaction](https://arxiv.org/abs/2104.10078) | [web](https://www.ea.com/seed/news/evaluating-data-driven-co-speech-gestures)

**2021 - Accepted papers**

- [Probabilistic Human-like Gesture Synthesis from Speech using GRU-based WGAN](https://openreview.net/forum?id=ykvm7OLh7B) | [video](https://www.youtube.com/watch?v=PMhjX6cdIPE)

- [Influence of Movement Energy and Affect Priming on the Perception of Virtual Characters Extroversion and Mood](https://openreview.net/forum?id=GjjPtEVdSLB)

- [Crossmodal clustered contrastive learning: Grounding of spoken language to gesture](https://openreview.net/forum?id=o8CpxaBurZQ) | [github](https://github.com/dondongwon/CC_NCE_GENEA)

- []()

**2020 - Accepted papers**

- [The StyleGestures entry to the GENEA Challenge 2020](https://genea-workshop.github.io/2020/downloads/Alexanderson2020StyleGestures.pdf) | [zendomo](https://zenodo.org/record/4088600#.ZBqRWNJByV4)

- [The FineMotion entry to the GENEA Challenge 2020](https://zenodo.org/record/4088609#.ZBqSB9JByV4)

- [Double-DCCCAE: Estimation of Sequential Body Motion Using Wave-Form - AlltheSmooth](https://zenodo.org/record/4088376#.ZBqR89JByV4)

- [CGVU: Semantics-guided 3D Body Gesture Synthesis](https://zenodo.org/record/4090879#.ZBqSHtJByV4)

- [Interpreting and Generating Gestures with Embodied Human Computer Interactions](https://zenodo.org/record/4088625#.ZBqSLtJByV4)

- [The Nectec Gesture Generation System entry to the GENEA Challenge 2020](https://zenodo.org/record/4088629#.ZBqSQ9JByV4)

</details>
<!-- ************************* GENEA Challenge ************************* -->

<!-- ************************* 2023 ************************* -->
<details open>
<summary>2023</summary>

- [A Comprehensive Review of Data-Driven Co-Speech Gesture Generation](https://arxiv.org/abs/2301.05339) | [github](https://github.com/google/mipnerf) | [web](https://www.ea.com/seed/news/genea-challenge-2022)
- []()
- []()
- []()
</details>
<!-- ************************* 2023 ************************* -->

<!-- ************************* 2022 ************************* -->
<details open>
<summary>2022</summary>

- [Evaluating Data-Driven Co-Speech Gestures of Embodied Conversational Agents through Real-Time Interaction](https://arxiv.org/abs/2104.10078)

- [ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech](https://arxiv.org/abs/2209.07556) | [github](https://github.com/ubisoft/ubisoft-laforge-ZeroEGGS) | [video](https://www.youtube.com/watch?v=EJPdTtVrxHo)

- [Voice2Face: Audio-Driven Facial and Tongue Rig Animations](https://media.contentapi.ea.com/content/dam/ea/seed/presentations/seed-sca2022-voice2face-paper.pdf) | [video](https://www.youtube.com/watch?v=R4CWYAQe4Zs) | [web](https://www.ea.com/seed/news/sca22-voice2face-audio-driven-facial-animation)

- [Deep Gesture Generation for Social Robots Using Type-Specific Libraries](https://arxiv.org/abs/2210.06790) | [video](https://www.youtube.com/watch?v=R4CWYAQe4Zs) | [web](https://www.ea.com/seed/news/sca22-voice2face-audio-driven-facial-animation)

- [The DeepMotion entry to the GENEA Challenge 2022](https://dl.acm.org/doi/abs/10.1145/3536221.3558059)

- [Automatic text‐to‐gesture rule generation for embodied conversational agents]() [video](https://www.youtube.com/watch?v=GIxaI9yTmMc)
</details>
<!-- ************************* 2022 ************************* -->
Gesture2Vec

<!-- ************************* 2021 ************************* -->
<details open>
<summary>2021</summary>

- [Evaluating Data-Driven Co-Speech Gestures of Embodied Conversational Agents](https://dl.acm.org/doi/abs/10.1145/3514197.3549697)

- [Multimodal analysis of the predictability of hand-gesture properties](https://arxiv.org/abs/2108.05762)

- [Deep Gesture Generation for Social Robots Using Type-Specific Libraries](https://arxiv.org/abs/2210.06790)

- [A Framework for Integrating Gesture Generation Models into Interactive Conversational Agents](https://arxiv.org/abs/2102.12302) | [video] (https://www.youtube.com/watch?v=jhgUBS0125A) | [homepage](https://nagyrajmund.github.io/project/gesturebot/) | [github](https://github.com/nagyrajmund/gesturebot)

- [Speech2Properties2Gestures: Gesture-Property Prediction as a Tool for Generating Representational Gestures from Speech](https://arxiv.org/abs/2106.14736) | [homepage](https://svito-zar.github.io/speech2properties2gestures/)

- [Moving Fast and Slow: Analysis of Representations and Post-Processing in Speech-Driven Automatic Gesture Generation](https://www.tandfonline.com/doi/full/10.1080/10447318.2021.1883883)

- []()
- []()
- []()
</details>
<!-- ************************* 2021 ************************* -->

<!-- ************************* 2020 ************************* -->
<details open>
<summary>2020</summary>

- [The GENEA Challenge 2020: A large, crowdsourced evaluation of gesture generation systems on common data](https://arxiv.org/abs/2102.11617) | [homepage](https://svito-zar.github.io/GENEAchallenge2020/) | [video](https://www.youtube.com/watch?v=QmaoKRzoVwM) | [video](https://www.youtube.com/watch?v=Y-5dgBQk34c) | [github](https://github.com/Svito-zar/genea_numerical_evaluations)

- [Gesticulator: A framework for semantically-aware speech-driven gesture generation](https://arxiv.org/abs/2001.09326) | | [video](https://www.youtube.com/watch?v=VQ8he6jjW08) | [github](https://github.com/Svito-zar/gesticulator) | [homepage](https://svito-zar.github.io/gesticulator/) | [dataset](https://figshare.com/projects/Gesticulator/87128)

- [Style-Controllable Speech-Driven Gesture Synthesis Using Normalising Flows]() | [video](https://www.youtube.com/watch?v=egf3tjbWBQE) | [github](https://github.com/simonalexanderson/StyleGestures)

- [Probabilistic Multi-modal Interlocutor-awa*re Generation of Facial Gestures in Dyadic Settings](https://arxiv.org/abs/2006.09888) | [video](https://www.youtube.com/watch?v=RhazMS4L_bk) | [homepage](https://jonepatr.github.io/lets_face_it/)

- [Can we trust online crowdworkers? Comparing online and offline participants in a preference test of virtual agents](https://arxiv.org/pdf/2009.10760.pdf)

- []()

- []()

</details>  
<!-- ************************* 2020 ************************* -->

<!-- ************************* 2019 ************************* -->
<details open>
<summary>2019</summary>

- [Analyzing Input and Output Representations for Speech-Driven Gesture Generation](https://arxiv.org/abs/1903.03369) | [github](https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder) | [video](https://www.youtube.com/watch?v=Iv7UBe92zrw) | [video](https://www.youtube.com/watch?v=tQLVyTVtsSU) | [homepage](https://svito-zar.github.io/audio2gestures/)

- [On the Importance of Representations for Speech-Driven Gesture Generation](https://www.ifaamas.org/Proceedings/aamas2019/pdfs/p2072.pdf)

- []()

- []()
</details>
<!-- ************************* 2019 ************************* -->

<!-- ************************* 2018 ************************* -->
<details open>
<summary>2018</summary>

- [A Neural Network Approach to Missing Marker Reconstruction in Human Motion Capture](https://arxiv.org/abs/1803.02665) | [video](https://www.youtube.com/watch?v=mi75gzEhbHI) | [video](https://www.youtube.com/watch?v=MFdFqxCNhN0) | [github](https://github.com/Svito-zar/NN-for-Missing-Marker-Reconstruction)

- [Data Driven Non-Verbal Behavior Generation for Humanoid Robots](https://dl.acm.org/doi/10.1145/3242969.3264970)

- [A Neural Network Approach to Missing Marker Reconstruction in Human Motion Capture](https://www.researchgate.net/publication/323626902_A_Neural_Network_Approach_to_Missing_Marker_Reconstruction_in_Human_Motion_Capture) | [github](https://github.com/Svito-zar/NN-for-Missing-Marker-Reconstruction) | [video](https://www.youtube.com/watch?v=mi75gzEhbHI)

- []()
</details>
<!-- ************************* 2018 ************************* -->

<!-- ************************* <2017 ************************* -->
<details open>
<summary><2017</summary>

- []()
</details>
<!-- ************************* <2017 ************************* -->

<!-- ************************* Others ************************* -->
<details open>
<summary>Others</summary>

- [Rig Inversion by Training a Differentiable Rig Function](https://arxiv.org/abs/2301.09567) | [video](https://www.youtube.com/watch?v=sYCz9LGIkuI)
</details>
<!-- ************************* Others ************************* -->

## <a name="dataset">Datasets</a>

- [PATS Dataset](https://chahuja.com/pats/)

## <a name="talks">Talks</a>

## <a name="toolkit">Toolkit</a>

- Algorithms
  - [SGToolkit: An Interactive Gesture Authoring Toolkit for Embodied Conversational Agents](https://github.com/ai4r/SGToolkit) | [homepage](https://uist.acm.org/uist2021/) | [video](https://www.youtube.com/watch?v=qClSOtLiVlc)

# Resources

Where to discover learning resources or new Gesture_Generation libraries.

## Books

- [Fluent Gesture_Generation](https://www.oreilly.com/library/view/fluent-Gesture_Generation/9781491946237/)
- [Think Gesture_Generation](https://greenteapress.com/wp/think-Gesture_Generation-2e/)

## Websites

- Tutorials
  - [Full Stack Gesture_Generation](https://www.fullstackGesture_Generation.com/)
  - [gesture_generation Cheatsheet](https://www.Gesture_Generationcheatsheet.org/)
  - [Real Gesture_Generation](https://realGesture_Generation.com)
  - [The Hitchhiker’s Guide to Gesture_Generation](https://docs.Gesture_Generation-guide.org/)
  - [Ultimate Gesture_Generation study guide](https://github.com/huangsam/ultimate-Gesture_Generation)
- Libraries
  - [Awesome Gesture_Generation @LibHunt](https://Gesture_Generation.libhunt.com/)
- Others
  - [gesture_generation ZEEF](https://Gesture_Generation.zeef.com/alan.richmond)
  - [gesture_generationic News](https://news.Gesture_Generation.sc/)
  - [What the f\*ck Gesture_Generation!](https://github.com/satwikkansal/wtfGesture_Generation)

## Talks

- [GDC 2020 - Machine Learning, Physics Simulation, Kolmogorov Complexity, and Squishy Bunnies](https://www.youtube.com/watch?v=sUb0W5_waRI)
- []()

# Contributing

## Implementations

#### Tensorflow

- [NeRF](https://github.com/bmild/nerf), Mildenhall et al., 2020 | [bibtex](./NeRF-and-Beyond.bib#L168-L173)
- [Nerual-Radiance-Fields](https://www.kaggle.com/code/ritzraha/nerual-radiance-fields), [@ariG23498](https://twitter.com/ariG23498), [@ritwik_raha](https://twitter.com/ritwik_raha), 2022

#### PyTorch

- [NeRF-PyTorch](https://github.com/yenchenlin/nerf-pytorch), Yen-Chen Lin, 2020 | [bibtex](./citations/pytorch-nerf.txt)
- [NeRF-PyTorch-Lighting](https://github.com/kwea123/nerf_pl), [@kwea123](https://github.com/kwea123), 2020
- [NeRF-W](https://github.com/kwea123/nerf_pl/tree/nerfw), [@kwea123](https://github.com/kwea123), 2021

## License

MIT
