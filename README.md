# Awesome Gesture Generation [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A curated list of Awesome **Gesture Generation** resources inspired by [awesome-NeRF](https://github.com/awesome-NeRF/awesome-NeRF).

## Table of Contents

- [1. Survey](#survey)
- [2. Papers](#papers)
- [3. Dataset](#dataset)
- [4. Toolkit](#toolkit)
- [5. Talks](#talks)
  - [Algorithms and Design Patterns](#algorithms-and-design-patterns)
  - [Audio](#audio)
- [5. Implementations](#implementations)
- [6. Resources](#resources)
  - [Books](#books)
  - [Newsletters](#newsletters)
  - [Podcasts](#podcasts)
  - [Websites](#websites)
- [Contributing](#contributing)

---

**PapersWithCode**
  - Gesture Generation : [https://paperswithcode.com/task/gesture-generation](https://paperswithcode.com/task/gesture-generation)

## <a name="survey">1. Survey</a>

<details open>
<summary>Comprehensive preview</summary>

- [A Comprehensive Review of Data-Driven Co-Speech Gesture Generation](https://arxiv.org/abs/2301.05339) | [github](https://github.com/google/mipnerf) | [web](https://www.ea.com/seed/news/genea-challenge-2022)

</details>

<details open>
<summary>GENEA Challenge</summary>

- [The GENEA Challenge 2022: A large evaluation of data-driven co-speech gesture generation](https://arxiv.org/abs/2208.10441) | [homepage](https://youngwoo-yoon.github.io/GENEAchallenge2022/) | [video](https://www.youtube.com/watch?v=4n02wXGGnd0)

- [GENEA Workshop 2021: The 2nd Workshop on Generation and Evaluation of Non-verbal Behaviour for Embodied Agents](https://dl.acm.org/doi/10.1145/3462244.3480983) | [homepage](https://genea-workshop.github.io/2021/)

- [The GENEA Challenge 2020: A large, crowdsourced evaluation of gesture generation systems on common data](https://arxiv.org/abs/2102.11617) | [homepage](https://svito-zar.github.io/GENEAchallenge2020/) | [video](https://www.youtube.com/watch?v=QmaoKRzoVwM) | [github](https://github.com/Svito-zar/genea_numerical_evaluations)
</details>

## <a name="papers">2. Papers</a>

<!-- ************************* Base-paper ************************* -->
<details open>
<summary>Base-paper</summary>

- [Mip-NeRF:](https://jonbarron.info/mipnerf/)
</details>
<!-- ************************* Base-paper ************************* -->



<!-- ************************* GENEA Challenge ************************* -->
<details open>
<summary>GENEA Challenge</summary>

- [Evaluating Data-Driven Co-Speech Gestures of Embodied Conversational Agents through Real-Time Interaction](https://arxiv.org/abs/2104.10078) | [web](https://www.ea.com/seed/news/evaluating-data-driven-co-speech-gestures)

- [Reconstruction](https://arxiv.org/abs/2106.10689) | [github](https://github.com/Totoro97/NeuS)
</details>
<!-- ************************* GENEA Challenge ************************* -->

<!-- ************************* 2022 ************************* -->
<details open>
<summary>2022</summary>

- [Evaluating Data-Driven Co-Speech Gestures of Embodied Conversational Agents through Real-Time Interaction](https://arxiv.org/abs/2104.10078)

- [ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech](https://arxiv.org/abs/2209.07556) | [github](https://github.com/ubisoft/ubisoft-laforge-ZeroEGGS) | [video](https://www.youtube.com/watch?v=EJPdTtVrxHo)

- [Voice2Face: Audio-Driven Facial and Tongue Rig Animations](https://media.contentapi.ea.com/content/dam/ea/seed/presentations/seed-sca2022-voice2face-paper.pdf) | [video](https://www.youtube.com/watch?v=R4CWYAQe4Zs) | [web](https://www.ea.com/seed/news/sca22-voice2face-audio-driven-facial-animation)

- [Deep Gesture Generation for Social Robots Using Type-Specific Libraries](https://arxiv.org/abs/2210.06790) | [video](https://www.youtube.com/watch?v=R4CWYAQe4Zs) | [web](https://www.ea.com/seed/news/sca22-voice2face-audio-driven-facial-animation)

- [The DeepMotion entry to the GENEA Challenge 2022](https://dl.acm.org/doi/abs/10.1145/3536221.3558059)

- [Automatic text‐to‐gesture rule generation for embodied conversational agents]() [video](https://www.youtube.com/watch?v=GIxaI9yTmMc)
</details>
<!-- ************************* 2022 ************************* -->
Gesture2Vec

<!-- ************************* 2021 ************************* -->
<details open>
<summary>2021</summary>

- [Evaluating Data-Driven Co-Speech Gestures of Embodied Conversational Agents](https://dl.acm.org/doi/abs/10.1145/3514197.3549697)

- [Multimodal analysis of the predictability of hand-gesture properties](https://arxiv.org/abs/2108.05762)

- [Deep Gesture Generation for Social Robots Using Type-Specific Libraries](https://arxiv.org/abs/2210.06790)
</details>
<!-- ************************* 2021 ************************* -->

<!-- ************************* 2020 ************************* -->
<details open>
<summary>2020</summary>

- [Gesticulator: A framework for semantically-aware speech-driven gesture generation](https://arxiv.org/abs/2001.09326) |  | [video](https://www.youtube.com/watch?v=VQ8he6jjW08) | [github](https://github.com/Svito-zar/gesticulator) | [homepage](https://svito-zar.github.io/gesticulator/) | [dataset](https://figshare.com/projects/Gesticulator/87128)
- [Style-Controllable Speech-Driven Gesture Synthesis Using Normalising Flows]() | [video](https://www.youtube.com/watch?v=egf3tjbWBQE) | [github](https://github.com/simonalexanderson/StyleGestures)
- [Probabilistic Multi-modal Interlocutor-aware Generation of Facial Gestures in Dyadic Settings](https://arxiv.org/abs/2006.09888) | [video](https://www.youtube.com/watch?v=RhazMS4L_bk) | [homepage](https://jonepatr.github.io/lets_face_it/)
- []()
- []()
- []()

</details>
<!-- ************************* 2020 ************************* -->


<!-- ************************* 2019 ************************* -->
<details open>
<summary>2019</summary>

- [Analyzing Input and Output Representations for Speech-Driven Gesture Generation](https://arxiv.org/abs/1903.03369) | [github](https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder) | [video](https://www.youtube.com/watch?v=Iv7UBe92zrw) | [video](https://www.youtube.com/watch?v=tQLVyTVtsSU)
- []()
- []()
- []()
</details>
<!-- ************************* 2019 ************************* -->


<!-- ************************* 2018 ************************* -->
<details open>
<summary>2018</summary>

- [A Neural Network Approach to Missing Marker Reconstruction in Human Motion Capture](https://arxiv.org/abs/1803.02665) | [video](https://www.youtube.com/watch?v=mi75gzEhbHI) | [video](https://www.youtube.com/watch?v=MFdFqxCNhN0) | [github](https://github.com/Svito-zar/NN-for-Missing-Marker-Reconstruction)
- []()
</details>
<!-- ************************* 2018 ************************* -->


<!-- ************************* <2017 ************************* -->
<details open>
<summary><2017</summary>

- []()
</details>
<!-- ************************* <2017 ************************* -->


<!-- ************************* Others ************************* -->
<details open>
<summary>Others</summary>

- [Rig Inversion by Training a Differentiable Rig Function](https://arxiv.org/abs/2301.09567) | [video](https://www.youtube.com/watch?v=sYCz9LGIkuI)
</details>
<!-- ************************* Others ************************* -->




## <a name="talks">Talks</a>

## <a name="toolkit">Toolkit</a>

- Algorithms
  - [SGToolkit: An Interactive Gesture Authoring Toolkit for Embodied Conversational Agents](https://github.com/ai4r/SGToolkit) | [homepage](https://uist.acm.org/uist2021/) | [video](https://www.youtube.com/watch?v=qClSOtLiVlc)

# Resources

Where to discover learning resources or new Gesture_Generation libraries.

## Books

- [Fluent Gesture_Generation](https://www.oreilly.com/library/view/fluent-Gesture_Generation/9781491946237/)
- [Think Gesture_Generation](https://greenteapress.com/wp/think-Gesture_Generation-2e/)

## Websites

- Tutorials
  - [Full Stack Gesture_Generation](https://www.fullstackGesture_Generation.com/)
  - [gesture_generation Cheatsheet](https://www.Gesture_Generationcheatsheet.org/)
  - [Real Gesture_Generation](https://realGesture_Generation.com)
  - [The Hitchhiker’s Guide to Gesture_Generation](https://docs.Gesture_Generation-guide.org/)
  - [Ultimate Gesture_Generation study guide](https://github.com/huangsam/ultimate-Gesture_Generation)
- Libraries
  - [Awesome Gesture_Generation @LibHunt](https://Gesture_Generation.libhunt.com/)
- Others
  - [gesture_generation ZEEF](https://Gesture_Generation.zeef.com/alan.richmond)
  - [gesture_generationic News](https://news.Gesture_Generation.sc/)
  - [What the f\*ck Gesture_Generation!](https://github.com/satwikkansal/wtfGesture_Generation)

## Talks

- [GDC 2020 - Machine Learning, Physics Simulation, Kolmogorov Complexity, and Squishy Bunnies](https://www.youtube.com/watch?v=sUb0W5_waRI)
- []()

# Contributing

## Implementations

#### Tensorflow

- [NeRF](https://github.com/bmild/nerf), Mildenhall et al., 2020 | [bibtex](./NeRF-and-Beyond.bib#L168-L173)
- [Nerual-Radiance-Fields](https://www.kaggle.com/code/ritzraha/nerual-radiance-fields), [@ariG23498](https://twitter.com/ariG23498), [@ritwik_raha](https://twitter.com/ritwik_raha), 2022

#### PyTorch

- [NeRF-PyTorch](https://github.com/yenchenlin/nerf-pytorch), Yen-Chen Lin, 2020 | [bibtex](./citations/pytorch-nerf.txt)
- [NeRF-PyTorch-Lighting](https://github.com/kwea123/nerf_pl), [@kwea123](https://github.com/kwea123), 2020
- [NeRF-W](https://github.com/kwea123/nerf_pl/tree/nerfw), [@kwea123](https://github.com/kwea123), 2021

## License

MIT
